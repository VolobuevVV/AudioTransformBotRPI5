from telegram import Update, InputFile, ReplyKeyboardMarkup, ParseMode
from telegram.ext import Updater, CommandHandler, MessageHandler, Filters, CallbackContext
from pydub import AudioSegment
import os
import whisper

BOT_TOKEN = '8101388926:AAEjCS7kwSp8EitsYo8m11rT4SeQzUsSf4M'

# –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
preloaded_models = {
    'tiny': whisper.load_model('tiny'),
    'base': whisper.load_model('base'),
    'small': whisper.load_model('small'),
}

user_models = {}

def start(update: Update, context: CallbackContext):
    user_name = update.message.from_user.first_name
    keyboard = [['–ò–∑–º–µ–Ω–∏—Ç—å –≥–æ–ª–æ—Å', '–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≥–æ–ª–æ—Å –≤ —Ç–µ–∫—Å—Ç']]
    reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
    update.message.reply_text(
        f'–ü—Ä–∏–≤–µ—Ç, {user_name}! üòä –û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∏ —è —Å–¥–µ–ª–∞—é —Å –Ω–∏–º —á—Ç–æ-–Ω–∏–±—É–¥—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ–µ!\n'
        '–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ - –í–ª–∞–¥–∏–º–∏—Ä –í–æ–ª–æ–±—É–µ–≤ @volobuevv üë®‚Äçüíª',
        reply_markup=reply_markup
    )
    context.user_data.clear()

def handle_text(update: Update, context: CallbackContext):
    text = update.message.text
    user_id = update.message.from_user.id

    if text == '–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≥–æ–ª–æ—Å –≤ —Ç–µ–∫—Å—Ç':
        context.user_data['action'] = 'recognize'
        keyboard = [['tiny', 'base', 'small'], ['–ù–∞–∑–∞–¥']]
        reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
        update.message.reply_text("–í—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏", reply_markup=reply_markup)

    elif text in ['tiny', 'base', 'small'] and context.user_data.get('action') == 'recognize':
        user_models[user_id] = text
        update.message.reply_text(f'–í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {text}\n–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ üéô')

    elif text == '–ò–∑–º–µ–Ω–∏—Ç—å –≥–æ–ª–æ—Å':
        context.user_data['action'] = 'transform'
        update.message.reply_text("–û—Ç–ø—Ä–∞–≤—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ")

    elif text == '–ù–∞–∑–∞–¥':
        context.user_data.pop('action', None)
        keyboard = [['–ò–∑–º–µ–Ω–∏—Ç—å –≥–æ–ª–æ—Å', '–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å –≥–æ–ª–æ—Å –≤ —Ç–µ–∫—Å—Ç']]
        reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
        update.message.reply_text("–í–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –Ω–∞–∑–∞–¥\n–í—ã–±–µ—Ä–∏ –¥–µ–π—Å—Ç–≤–∏–µ", reply_markup=reply_markup)

def transcribe_audio(audio_file, model_name):
    model = preloaded_models[model_name]
    result = model.transcribe(audio_file, language="ru")
    return result["text"]

def voice(update: Update, context: CallbackContext):
    action = context.user_data.get('action')
    user_id = update.message.from_user.id
    model_name = user_models.get(user_id, 'tiny')

    if not action:
        update.message.reply_text("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏ –¥–µ–π—Å—Ç–≤–∏–µ —Å –ø–æ–º–æ—â—å—é –∫–Ω–æ–ø–æ–∫")
        return

    # –°–æ–æ–±—â–µ–Ω–∏–µ –æ –Ω–∞—á–∞–ª–µ –ø—Ä–æ—Ü–µ—Å—Å–∞
    message = update.message.reply_text(
        "üåÄ –û–∂–∏–¥–∞–π—Ç–µ... –†–∞—Å–ø–æ–∑–Ω–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.",
        parse_mode=ParseMode.MARKDOWN
    )

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    file = update.message.voice.get_file()
    file_path = "voice.ogg"
    file.download(file_path)

    if action == 'transform':
        sound = AudioSegment.from_ogg(file_path)
        octaves = -0.5
        new_sample_rate = int(sound.frame_rate * (2 ** octaves))
        sound = sound._spawn(sound.raw_data, overrides={'frame_rate': new_sample_rate})
        sound = sound.set_frame_rate(44100).set_channels(1)

        output_ogg_path = "voice_lowered.ogg"
        output_wav_path = "voice_lowered.wav"
        sound.export(output_ogg_path, format="ogg")
        sound.export(output_wav_path, format="wav")

        with open(output_ogg_path, 'rb') as f:
            update.message.reply_voice(voice=InputFile(f), caption="–í–æ—Ç —Ç–≤–æ–π –≥–æ–ª–æ—Å —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–º —Ç–æ–Ω–æ–º")

        with open(output_wav_path, 'rb') as f:
            update.message.reply_document(document=InputFile(f))

        os.remove(output_ogg_path)
        os.remove(output_wav_path)

    elif action == 'recognize':
        text = transcribe_audio(file_path, model_name)
        update.message.reply_text(text)

    os.remove(file_path)

    # –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–∂–∏–¥–∞–Ω–∏—è
    message.delete()

    context.user_data.clear()  # –û—á–∏—Å—Ç–∏–º –¥–∞–Ω–Ω—ã–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è

def main():
    updater = Updater(BOT_TOKEN)
    dispatcher = updater.dispatcher
    dispatcher.add_handler(CommandHandler("start", start))
    dispatcher.add_handler(MessageHandler(Filters.voice, voice))
    dispatcher.add_handler(MessageHandler(Filters.text & ~Filters.command, handle_text))
    updater.start_polling()
    updater.idle()

if __name__ == '__main__':
    main()
